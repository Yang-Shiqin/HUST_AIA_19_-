{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python\r\n",
    "# coding=utf-8\r\n",
    "import torch\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "\r\n",
    "# 想不到怎么写比较好\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# x(N, d)\r\n",
    "# y(N, )\r\n",
    "# w(d, )\r\n",
    "# b(N, )\r\n",
    "class LinearRegression():\r\n",
    "    def __init__(self, N, in_dim):\r\n",
    "        self.w = torch.rand(in_dim+1)*1e-5\r\n",
    "\r\n",
    "    def loss(self, x, y):\r\n",
    "        return ((torch.mv(x, self.w).reshape(-1,1)-y.reshape(-1, 1))**2).sum()\r\n",
    "\r\n",
    "    def backword(self, x, y):\r\n",
    "        tmp = torch.mv(x, self.w).reshape(-1)-y\r\n",
    "        dw = 2*torch.mv(x.t(), tmp)\r\n",
    "        return dw\r\n",
    "\r\n",
    "    # common    : 梯度下降法\r\n",
    "    # SGD       : 随机梯度下降法    beta1-采样比例\r\n",
    "    # M         : 动量法            beta1\r\n",
    "    # Ada       : Adagrad           beta1\r\n",
    "    # RMS       : RMSProp           beta1 beta2\r\n",
    "    # Adam      : Adam              beta1 beta2\r\n",
    "    def update_grad(self, x, y, lr, method='common', beta1=0.9, beta2=0.999, it=100, batch_size=128):\r\n",
    "        N, d = x.shape\r\n",
    "        \r\n",
    "        los = []\r\n",
    "        if method=='common':\r\n",
    "            for i in range(it):\r\n",
    "                dw= self.backword(x, y)\r\n",
    "                self.w -= lr*dw\r\n",
    "                los.append(self.loss(x, y))\r\n",
    "        elif method=='SGD':\r\n",
    "            for i in range(it):\r\n",
    "                idx = torch.randperm(N)\r\n",
    "                for j in range(N//batch_size+1):\r\n",
    "                    batch_x = x[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                    batch_y = y[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                    dw= self.backword(batch_x, batch_y)\r\n",
    "                    self.w -= lr*dw\r\n",
    "                los.append(self.loss(x, y))\r\n",
    "        else:\r\n",
    "            v1 = 0\r\n",
    "            v2 = 0\r\n",
    "            if method=='M':     # 形状奇怪\r\n",
    "                for i in range(it):\r\n",
    "                    idx = torch.randperm(N)\r\n",
    "                    for j in range(N//batch_size+1):\r\n",
    "                        batch_x = x[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                        batch_y = y[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                        dw = self.backword(batch_x, batch_y)\r\n",
    "                        v1 += beta1*dw\r\n",
    "                        self.w -= lr*v1\r\n",
    "                    los.append(self.loss(x, y))\r\n",
    "            elif method=='Ada':\r\n",
    "                for i in range(it):\r\n",
    "                    idx = torch.randperm(N)\r\n",
    "                    for j in range(N//batch_size+1):\r\n",
    "                        batch_x = x[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                        batch_y = y[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                        dw= self.backword(batch_x, batch_y)\r\n",
    "                        v1 = dw\r\n",
    "                        v2 += v1**2\r\n",
    "                        self.w -= lr*v1/torch.sqrt(v2+1e-7)\r\n",
    "                    los.append(self.loss(x, y))\r\n",
    "            elif method=='RMS':       # NAN\r\n",
    "                for i in range(it):\r\n",
    "                    idx = torch.randperm(N)\r\n",
    "                    for j in range(N//batch_size+1):\r\n",
    "                        batch_x = x[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                        batch_y = y[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                        dw = self.backword(batch_x, batch_y)\r\n",
    "                        v1 = beta1*dw+(1-beta1)*dw**2\r\n",
    "                        self.w -= lr*dw/torch.sqrt(v1+1e-7)\r\n",
    "                    los.append(self.loss(x, y))\r\n",
    "            elif method=='Adam':\r\n",
    "                for i in range(it):\r\n",
    "                    idx = torch.randperm(N)\r\n",
    "                    for j in range(N//batch_size+1):\r\n",
    "                        batch_x = x[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                        batch_y = y[idx[j*batch_size:min(N, (j+1)*batch_size)]]\r\n",
    "                        dw = self.backword(batch_x, batch_y)\r\n",
    "                        v1 = v1*beta1+(1-beta1)*dw\r\n",
    "                        v2 = beta2*v2+(1-beta2)*dw**2\r\n",
    "                        self.w -= lr*v1/torch.sqrt(v2+1e-7)\r\n",
    "                    los.append(self.loss(x, y))\r\n",
    "        return los\r\n",
    "\r\n",
    "    def train(self, x, y, lr=0.01, method='common', beta1=0.9, beta2=0.999, it=100, batch_size=100, is_draw=\"True\"):\r\n",
    "        N, _ = x.shape\r\n",
    "        x = torch.cat((torch.ones(N).reshape(-1, 1), x), dim=1)\r\n",
    "        # print('times: 0, loss: ', loss_tmp)\r\n",
    "        los = self.update_grad(x, y, lr, method, beta1, beta2, it, batch_size)\r\n",
    "        print(\"loss: \", los)\r\n",
    "        plt.plot(range(len(los)), los)\r\n",
    "        plt.show()\r\n",
    "        if is_draw and self.w.shape[0]==2:\r\n",
    "            plt.plot(x[:,1], y, 'ro')\r\n",
    "            xx = torch.linspace(torch.min(x[:,1]), torch.max(x[:,1]))\r\n",
    "            yy = xx*self.w[1]+self.w[0]\r\n",
    "            plt.plot(xx, yy)\r\n",
    "            plt.show()\r\n",
    "        return self.w\r\n",
    "\r\n",
    "    # 只有做分类时用到这个\r\n",
    "    def classify_draw(self, pos_x, neg_x, test_pos_x=None, test_neg_x=None):\r\n",
    "        if pos_x.shape[1]==2:\r\n",
    "            plt.plot(pos_x[:, 0], pos_x[:, 1], 'bo')\r\n",
    "            plt.plot(neg_x[:, 0], neg_x[:, 1], 'rx')\r\n",
    "            if test_pos_x!=None:\r\n",
    "                plt.plot(test_pos_x[:, 0], test_pos_x[:, 1], 'c^')\r\n",
    "                plt.plot(test_neg_x[:, 0], test_neg_x[:, 1], 'y*')\r\n",
    "            min_x = torch.min(torch.min(pos_x[:, 0]), torch.min(neg_x[:, 0])).item()\r\n",
    "            max_x = torch.max(torch.min(pos_x[:, 0]), torch.max(neg_x[:, 0])).item()\r\n",
    "            xx = torch.linspace(min_x, max_x)\r\n",
    "            w0, w1, w2 = self.w\r\n",
    "            yy = -(w1*xx+w0)/w2\r\n",
    "            plt.plot(xx, yy)\r\n",
    "            plt.show()\r\n",
    "        correct_num = sum(torch.sign(self.predict(pos_x))==1)+sum(torch.sign(self.predict(neg_x))==-1)\r\n",
    "        rate = correct_num/(pos_x.shape[0]+neg_x.shape[0])\r\n",
    "        print(\"train: correct rate: \", rate)\r\n",
    "        if test_pos_x!=None:\r\n",
    "            test_correct_num = sum(torch.sign(self.predict(test_pos_x))==1)+sum(torch.sign(self.predict(test_neg_x))==-1)\r\n",
    "            test_rate = test_correct_num/(test_pos_x.shape[0]+test_neg_x.shape[0])\r\n",
    "            print(\"test: correct rate: \", test_rate)\r\n",
    "            return [rate, test_rate]\r\n",
    "        return rate\r\n",
    "\r\n",
    "    def predict(self, x):\r\n",
    "        N = x.shape[0]\r\n",
    "        x = torch.cat((torch.ones(N).reshape(-1, 1), x), dim=1)\r\n",
    "        return torch.mv(x, self.w)\r\n",
    "\r\n",
    "    def math_method(self, x, y):\r\n",
    "        x = torch.cat((torch.ones(x.shape[0],1).reshape(-1,1), x), dim=1)\r\n",
    "        return torch.mm(torch.mm(torch.linalg.inv(torch.mm(x.t(), x)), x.t()), y.reshape(-1, 1))\r\n",
    "\r\n",
    "D = torch.tensor([  [0.2, 0.7, 1], \r\n",
    "                    [0.3, 0.3, 1], \r\n",
    "                    [0.4, 0.5, 1], \r\n",
    "                    [0.6, 0.5, 1], \r\n",
    "                    [0.1, 0.4, 1], \r\n",
    "                    [0.4, 0.6, -1], \r\n",
    "                    [0.6, 0.2, -1], \r\n",
    "                    [0.7, 0.4, -1],\r\n",
    "                    [0.8, 0.6, -1],\r\n",
    "                    [0.7, 0.5, -1]])\r\n",
    "x = D[:, :2]\r\n",
    "y = D[:, 2]\r\n",
    "\r\n",
    "model = LinearRegression(x.shape[0], x.shape[1])\r\n",
    "print(model.train(x, y, method='common'))\r\n",
    "print(model.math_method(x, y))\r\n",
    "model.classify_draw(D[:5, :2], D[5:, :2])\r\n",
    "model.predict(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import random\r\n",
    "# from LinearRegression import LinearRegression\r\n",
    "\r\n",
    "pos_x = torch.randn(200, 2)+torch.tensor([-5, 0])\r\n",
    "neg_x = torch.randn(200, 2)+torch.tensor([0, 5])\r\n",
    "x = torch.cat((pos_x, neg_x), dim=0)\r\n",
    "pos_y = torch.ones(200,)\r\n",
    "neg_y = -torch.ones(200,)\r\n",
    "y = torch.cat((pos_y, neg_y), dim=0)\r\n",
    "N, d = pos_x.shape\r\n",
    "idx = [i for i in range(2*N)]\r\n",
    "random.shuffle(idx)\r\n",
    "train_x, train_y = x[idx[:int(2*N*0.8)]], y[idx[:int(2*N*0.8)]]\r\n",
    "test_x, test_y = x[idx[int(2*N*0.8):]], y[idx[int(2*N*0.8):]]\r\n",
    "model = LinearRegression(int(2*N*0.8), d)\r\n",
    "print(model.train(train_x, train_y, method='Ada', it=2000, lr = 0.01))    # w\r\n",
    "\r\n",
    "model.classify_draw(train_x[train_y==1], train_x[train_y==-1], test_x[test_y==1], test_x[test_y==-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import random\r\n",
    "# from LinearRegression import LinearRegression\r\n",
    "\r\n",
    "pos_x = torch.randn(200, 2)+torch.tensor([1, 0])\r\n",
    "neg_x = torch.randn(200, 2)+torch.tensor([0, 1])\r\n",
    "x = torch.cat((pos_x, neg_x), dim=0)\r\n",
    "pos_y = torch.ones(200,)\r\n",
    "neg_y = -torch.ones(200,)\r\n",
    "y = torch.cat((pos_y, neg_y), dim=0)\r\n",
    "N, d = pos_x.shape\r\n",
    "idx = [i for i in range(2*N)]\r\n",
    "random.shuffle(idx)\r\n",
    "train_x, train_y = x[idx[:int(2*N*0.8)]], y[idx[:int(2*N*0.8)]]\r\n",
    "test_x, test_y = x[idx[int(2*N*0.8):]], y[idx[int(2*N*0.8):]]\r\n",
    "model = LinearRegression(int(2*N*0.8), d)\r\n",
    "print(model.train(train_x, train_y, method='Ada', it=2000, lr = 0.01))    # w\r\n",
    "\r\n",
    "model.classify_draw(train_x[train_y==1], train_x[train_y==-1], test_x[test_y==1], test_x[test_y==-1])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}